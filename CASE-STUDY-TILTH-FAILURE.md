# Case Study: TILTH (The Failure)

## What We Built

An internal prototype for ethical design training using AI to generate synthetic "data exhaust" — the kind of contextual debris that would normally accumulate from real user interactions, real workplace conflicts, real decisions made under pressure.

### The Layers

**Layer 1: Role Decks**
Eight character profiles with names, roles, personality radar charts, ethical scores, identity archetypes. Maya Chen the Silenced Educator. Dev Patel the Overruled Engineer. Each one complete with backstory, motivations, vulnerabilities.

**Layer 2: Personas & Scenarios**
Workplace dilemmas at a fictional agricultural tech company called Agronica. Products with names like GrowthPath, YieldMatch, ConsentGarden. Each scenario: a protagonist, an antagonist, a systemic pressure, a decision point.

**Layer 3: Negotiation Simulations**
The CB-Box — an AI-powered role-play simulator where users practice difficult conversations. System prompts for "allies" and "keepers." Personality traits that drift during conversation. Feedback loops.

**Layer 4: Analytical Frameworks**
McLuhan's Tetrad applied to design ethics. Enhance, Obsolesce, Retrieve, Reverse. Four directions for each of eight scenarios. Thirty-two analytical pathways.

**Layer 5: Educational Infrastructure**
Opening animations. Video placeholders with detailed generation prompts. Technical briefs. Quizzes with five response options each, career risk percentages, systemic analysis per outcome.

**Layer 6: Meta-Analysis**
Meadows' Leverage Points mapped to the system. Wong's Infrastructure Mapping applied. JSON files documenting what exists, what's partial, what's missing. A taxonomy of our own incompleteness.

**Layer 7: Navigation**
Portals, indexes, accordions, split-views. Each iteration trying to make the previous layers navigable. Each solution adding another layer.

---

## Why It Failed

### "Complexity Grey"

The phrase we kept coming back to: *couldn't tell broken from designed.*

When a link didn't work, was it:
- A bug we introduced?
- A file the AI generated with the wrong name?
- A feature we hadn't built yet?
- A placeholder we forgot was a placeholder?
- An intentional gap in the prototype?

The grey was everywhere. Every surface looked complete enough to be intentional, incomplete enough to be broken.

### Context Exceeded Coherence

Each LLM generation added context:
- "Here's a detailed persona for Episode 4"
- "Here's a satirical essay exposing the structural logic"
- "Here's evidence files with interactive SVG animations"
- "Here's a JSON analysis applying systems thinking"

The AI never said no. It never said "this is too much." It never said "you've lost the thread." It simply produced more. And we accepted more because production felt like progress.

We were drowning in articulate, internally-consistent, mutually-incoherent content.

### The Scene Became Unnavigable

By the end:
- 8 episode folders with 4-5 files each
- 8 episode-complete.html files
- 8 opening animation files
- Character profiles in JS, galleries in HTML, catalogs with radar charts
- Leverage analysis in JSON
- Multiple portal designs, each obsoleting the last
- Documentation that documented documentation

A user arriving at this system would face the same question we faced: *Where do I start? What is this? Why are there so many things?*

The navigation problem was not a UI problem. It was a content problem. We had built a library for a book that didn't exist yet.

---

## The Deeper Failure

### We Built Infrastructure for Imaginary Users

The personas were detailed. The scenarios were nuanced. The ethical dilemmas were genuinely difficult. But we had never validated:
- Do people want to practice workplace negotiations with AI?
- Does role-playing change behavior?
- Is the Tetrad framework useful for designers who aren't already McLuhan readers?
- Would anyone use a quiz with five options when they could just skip to the "right" answer?

We built elaborate rooms for guests we hadn't invited.

### Generative AI Enables Premature Scaling

The old constraint was labor. You couldn't build eight detailed scenarios, eight personas, eight analytical frameworks — not alone, not quickly. The labor cost enforced focus. You'd build one scenario deeply before building a second.

AI removed that constraint. We could spin up all eight scenarios simultaneously. We could generate essays, quizzes, evidence files as fast as we could write prompts. The constraint became attention, but we didn't notice until attention had already been exceeded.

### Coherence is Not Additive

Each piece we generated was coherent on its own terms:
- The personas were internally consistent
- The scenarios were dramatically structured
- The Tetrad analysis was philosophically grounded
- The infrastructure mapping was methodologically sound

But coherence doesn't add. You can't stack coherent pieces and expect a coherent whole. The whole requires something the pieces don't contain: a singular vision that knows what to exclude.

We never excluded anything.

---

## What Would Have Worked

### One Episode, Actually Complete
Build Episode 01 to completion. Real video, not placeholders. Tested quiz, not theoretical. User feedback, not assumed engagement. Then: does anyone want Episode 02?

### Navigation Before Content
Before generating eight scenarios, build the interface for one. Does the CB-Box negotiation simulator actually help someone? Test with real users. The content could have been placeholder text — the interaction design was the hypothesis.

### Constraints as Features
"We only have one scenario" is a feature, not a limitation. It forces the scenario to be good. It forces users to engage deeply with one dilemma before encountering another. It makes the experience navigable by making it small.

### Generative AI for Iteration, Not Generation
Use AI to refine one scenario across ten passes, not to generate ten scenarios in one pass. Use it to find weaknesses in existing content, not to create new content that obscures the weaknesses.

---

## The Artifact

What remains is instructive as a failure case:
- **PORTAL.html**: Seven iterations of the same unsolved problem
- **leverage-infrastructure-analysis.json**: A map of a territory that never became real
- **character-profiles.js**: Eight detailed people who never met a user
- **8 episode folders**: More content than any user would navigate

The prototype is complete in the way a maze is complete: every path leads somewhere, no path leads out.

---

## Coda

The name was always a warning we didn't hear.

**TILTH**: the condition of soil that has been prepared for planting. We spent all our time preparing the soil. We never planted anything.

The AI helped us till endlessly. It was very good at tilling. We asked for more till, and it gave us more till. The field is perfectly prepared, stretching to the horizon, and nothing grows there.

---

*Written December 2025, after the fifth attempt to make the portal navigable.*
